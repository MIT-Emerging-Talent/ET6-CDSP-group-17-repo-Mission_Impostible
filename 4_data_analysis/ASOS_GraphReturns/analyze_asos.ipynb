{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# Load the prepared data\n",
        "prepared_data_path = 'C:/Users/ADMIN/ET6-CDSP-group-17-repo/2_data_preparation/ASOS_GraphReturns/prepared_asos_data.csv'\n",
        "try:\n",
        "    df = pd.read_csv(prepared_data_path)\n",
        "    print(f\"Successfully loaded prepared data from {prepared_data_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: {prepared_data_path} not found. Please ensure the data preparation step was completed.\")\n",
        "    exit()\n",
        "\n",
        "print(\"\n--- Initial Data Overview for Analysis ---\")\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define features (X) and target (y)\n",
        "# Drop ID columns and the target variable from features\n",
        "# Ensure to drop any columns that were not one-hot encoded but are categorical strings\n",
        "# Check for columns that might have been left as objects after one-hot encoding in preparation\n",
        "object_cols = df.select_dtypes(include='object').columns.tolist()\n",
        "cols_to_drop = ['customer_id', 'variant_id', 'product_id', 'supplier_ref_id', 'isReturned'] + object_cols\n",
        "\n",
        "# Filter out columns that don't exist in the DataFrame\n",
        "cols_to_drop = [col for col in cols_to_drop if col in df.columns]\n",
        "\n",
        "X = df.drop(columns=cols_to_drop, errors='ignore')\n",
        "y = df['isReturned']\n",
        "\n",
        "print(\"\n--- Features and Target Variable Setup ---\")\n",
        "print(\"Features (X) shape:\", X.shape)\n",
        "print(\"Target (y) shape:\", y.shape)\n",
        "print(\"X columns (first 10):\", X.columns.tolist()[:10])\n",
        "print(\"y value counts:\n\", y.value_counts())\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(\"\n--- Train-Test Split ---\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train value counts:\n\", y_train.value_counts(normalize=True))\n",
        "print(\"y_test value counts:\n\", y_test.value_counts(normalize=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and train the RandomForestClassifier model\n",
        "# Using parameters from the original notebook for consistency, but can be tuned\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1) # n_jobs=-1 to use all available cores\n",
        "\n",
        "print(\"\n--- Training RandomForestClassifier Model ---\")\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Model training complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)[:, 1] # Probabilities for the positive class (isReturned = 1)\n",
        "\n",
        "print(\"\n--- Model Evaluation ---\")\n",
        "print(\"Classification Report:\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve and AUC\n",
        "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Importance\n",
        "importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "top_features = importances.sort_values(ascending=False).head(15)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.barplot(x=top_features.values, y=top_features.index, palette='viridis')\n",
        "plt.title('Top 15 Features Influencing Product Returns')\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.gca().invert_yaxis() # Invert y-axis to have the most important feature at the top\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
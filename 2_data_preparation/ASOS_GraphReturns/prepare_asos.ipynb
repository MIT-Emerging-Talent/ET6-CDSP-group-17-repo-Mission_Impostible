{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define the path to the data files (assuming they are in the MIT Data Science/CSV Files subfolder)\n",
        "data_path = 'C:/Users/ADMIN/ET6-CDSP-group-17-repo/1_datasets/MIT Data Science/CSV Files/'\n",
        "\n",
        "# List of file names\n",
        "file_names = [\n",
        "    'customer_nodes_training.csv',\n",
        "    'event_table_training.csv',\n",
        "    'product_nodes_training.csv'\n",
        "]\n",
        "\n",
        "# Dictionary to store loaded dataframes\n",
        "loaded_data = {}\n",
        "\n",
        "# Load each CSV file\n",
        "for name in file_names:\n",
        "    file_path = os.path.join(data_path, name)\n",
        "    try:\n",
        "        loaded_data[name] = pd.read_csv(file_path)\n",
        "        print(f\"Successfully loaded {name}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: {file_path} not found. Please ensure the path is correct.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {name}: {e}\")\n",
        "\n",
        "# Assign dataframes to variables for easier access\n",
        "customer_nodes = loaded_data['customer_nodes_training.csv']\n",
        "event_table = loaded_data['event_table_training.csv']\n",
        "product_nodes = loaded_data['product_nodes_training.csv']\n",
        "\n",
        "print(\"\n--- Initial DataFrames Loaded ---\")\n",
        "print(\"Customer Nodes Shape:\", customer_nodes.shape)\n",
        "print(\"Event Table Shape:\", event_table.shape)\n",
        "print(\"Product Nodes Shape:\", product_nodes.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge event_table with customer_nodes\n",
        "merged_df = event_table.merge(customer_nodes, on='hash(customerId)', how='left')\n",
        "\n",
        "# Merge the result with product_nodes\n",
        "merged_df = merged_df.merge(product_nodes, on='hash(variantID)', how='left')\n",
        "\n",
        "print(\"\n--- Merged DataFrame Info ---\")\n",
        "print(\"Merged DataFrame Shape:\", merged_df.shape)\n",
        "print(\"Columns after merge:\", merged_df.columns.tolist())\n",
        "print(\"Missing values after merge:\n\", merged_df.isnull().sum()[merged_df.isnull().sum() > 0])\n",
        "print(\"First 5 rows of merged DataFrame:\n\", merged_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rename columns for clarity (optional but good practice)\n",
        "merged_df.rename(columns={\n",
        "    'hash(customerId)': 'customer_id',\n",
        "    'hash(variantID)': 'variant_id',\n",
        "    'hash(productID)': 'product_id',\n",
        "    'hash(supplierRef)': 'supplier_ref_id'\n",
        "}, inplace=True)\n",
        "\n",
        "print(\"\n--- DataFrame after Renaming Columns ---\")\n",
        "print(\"Columns after renaming:\", merged_df.columns.tolist())\n",
        "print(\"First 5 rows with new column names:\n\", merged_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Handle categorical variables (if not already one-hot encoded)\n",
        "# Based on exploration, many categorical features are already one-hot encoded (e.g., Country_A, productType_B)",
        "# However, 'shippingCountry', 'productType', 'brandDesc' might still be present as original categorical columns.\n",
        "# Let's check and apply one-hot encoding if needed.\n",
        "\n",
        "# Identify categorical columns that are not already one-hot encoded\n",
        "categorical_cols = ['shippingCountry', 'productType', 'brandDesc']\n",
        "\n",
        "# Filter to only include columns that actually exist in the DataFrame\n",
        "categorical_cols_to_encode = [col for col in categorical_cols if col in merged_df.columns]\n",
        "\n",
        "if categorical_cols_to_encode:\n",
        "    print(f\"\n--- One-Hot Encoding Categorical Columns: {categorical_cols_to_encode} ---\")\n",
        "    merged_df = pd.get_dummies(merged_df, columns=categorical_cols_to_encode, drop_first=True)\n",
        "    print(\"Columns after one-hot encoding:\", merged_df.columns.tolist())\n",
        "else:\n",
        "    print(\"\nNo additional categorical columns to one-hot encode.\")\n",
        "\n",
        "print(\"\n--- Final DataFrame Info after Preparation ---\")\n",
        "print(\"Final DataFrame Shape:\", merged_df.shape)\n",
        "print(\"Final DataFrame Columns:\", merged_df.columns.tolist())\n",
        "print(\"Final Missing Values:\n\", merged_df.isnull().sum()[merged_df.isnull().sum() > 0])\n",
        "print(\"Final Data Types:\n\", merged_df.info())\n",
        "\n",
        "# Save the prepared DataFrame for later use\n",
        "output_dir = 'C:/Users/ADMIN/ET6-CDSP-group-17-repo/2_data_preparation/ASOS_GraphReturns/'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "output_file_path = os.path.join(output_dir, 'prepared_asos_data.csv')\n",
        "merged_df.to_csv(output_file_path, index=False)\n",
        "print(f\"\nPrepared data saved to: {output_file_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
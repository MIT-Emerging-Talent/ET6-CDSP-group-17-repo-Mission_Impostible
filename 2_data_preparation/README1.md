# üõçÔ∏è E-commerce Product Return Analysis ‚Äì Data Preparation

This repository contains data preparation workflows for two e-commerce datasets used in product return prediction projects:

1. **ASOS GraphReturns Dataset**
2. **TheLook E-commerce Dataset**

Both notebooks clean, merge, and engineer modeling-ready datasets for downstream machine learning tasks such as return classification.

---

## üì¶ Dataset 1: ASOS GraphReturns ‚Äì Data Preparation

### üóÇ Overview

This phase prepares the **ASOS GraphReturns** training dataset by merging event, customer, and product node tables into a single structured CSV for modeling.

### üìÅ Input Files

Uploaded via Google Colab interface:
- `event_table_training.p`
- `customer_nodes_training.p`
- `product_nodes_training.p`

### üß™ Output File
- `asos_merged_training.csv` ‚Äî the merged and cleaned training dataset.

### üìå Key Steps

| Step | Description |
|------|-------------|
| üì• Upload | Use `files.upload()` in Google Colab to load `.p` files |
| üì¶ Deserialize | Load files with `pd.read_pickle` |
| üîó Merge | Join tables on `customer_id_hashed` and `variant_id_hashed` |
| üè∑Ô∏è Rename | Convert hashed and cryptic column names into human-readable ones |
| üíæ Save | Export merged dataset to `.csv` for analysis |

### ‚úÖ Dependencies

- `pandas`
- `pickle`
- `pathlib`

> ‚ö†Ô∏è Run in **Google Colab** for compatibility with the file upload widget, or adapt to local workflows.

### ‚ñ∂Ô∏è How to Run

1. Open `01_data_preparation.ipynb` in **Google Colab**.
2. Upload the `.p` files when prompted.
3. The notebook will output `asos_merged_training.csv`.

### üìä Merging Process Diagram

```
[customer_nodes]      [product_nodes]
       \                   /
        \                 /
        [ event_table ]  <== merge on customerId and variantID
               |
               v
     asos_merged_training.csv
```

---

## üì¶ Dataset 2: TheLook E-commerce ‚Äì Data Preparation

### üìë What This Notebook Does

Prepares a clean feature set from **TheLook e-commerce** dataset with return labels and engineered features.

### üìÅ Input Files

Located under `1_datasets/thelook_Ecommerce/`:
- `distribution_centers.csv`
- `order_items.csv`
- `products.csv`
- `users.csv`

### üß™ Output File
- `thelook_returns_features.csv` ‚Äî modeling-ready feature set with `RETURN_FLAG` as the target.

### üìå Key Steps

| Step | Action | Description |
|------|--------|-------------|
| 1Ô∏è‚É£ | Load CSVs | Read 4 raw data files |
| 2Ô∏è‚É£ | Clean & Engineer | Add features like return flag, discount %, basket size, tenure, and shipping latency |
| 3Ô∏è‚É£ | Select Columns | Retain only necessary features for modeling |
| 4Ô∏è‚É£ | Save Output | Write to `thelook_returns_features.csv` |

### üéØ Target Variable

- `RETURN_FLAG`  
  - `1` = returned  
  - `0` = kept

### üöÄ How to Run

1. Clone the repository and install required libraries:
   ```bash
   pip install pandas numpy matplotlib ipython
   ```
2. Open `TheLook_Data_Preparation.ipynb` in Jupyter Notebook or VS Code.
3. Run all cells.
4. Check the output file in `2_data_preparation/theLook_Ecommerce/`.

### ‚ö†Ô∏è Notes & Assumptions

- Relative paths used‚Äîno hardcoded user directories.
- Missing timestamps ‚Üí `NaT`; numeric errors ‚Üí `NaN`.
- `discount_percent` clipped to range `[0, 1]`.
- `season` feature derived from month using a simple mapping.

---

## üìÅ Folder Structure

```
project_root/
‚îÇ
‚îú‚îÄ‚îÄ 1_datasets/
‚îÇ   ‚îî‚îÄ‚îÄ thelook_Ecommerce/
‚îÇ       ‚îú‚îÄ‚îÄ distribution_centers.csv
‚îÇ       ‚îú‚îÄ‚îÄ order_items.csv
‚îÇ       ‚îú‚îÄ‚îÄ products.csv
‚îÇ       ‚îî‚îÄ‚îÄ users.csv
‚îÇ
‚îú‚îÄ‚îÄ 2_data_preparation/
‚îÇ   ‚îú‚îÄ‚îÄ asos_graphreturns/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 01_data_preparation.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ thelook_Ecommerce/
‚îÇ       ‚îú‚îÄ‚îÄ TheLook_Data_Preparation.ipynb
‚îÇ       ‚îî‚îÄ‚îÄ thelook_returns_features.csv
‚îÇ
‚îî‚îÄ‚îÄ README.md  ‚Üê (You are here)
```

---

## üì¨ Contact

For questions or collaboration, feel free to open an issue or submit a pull request.

---

## üìú License

This project is for educational and research purposes. Refer to individual dataset licenses and terms of use before commercial application.